{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MODEL_PATH = \"models/autoencoder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(24, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(12, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(12, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(12, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(12, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(24, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/150\n",
      "60000/60000 [==============================] - 116s 2ms/sample - loss: 0.6936 - val_loss: 0.6920\n",
      "Epoch 2/150\n",
      "60000/60000 [==============================] - 123s 2ms/sample - loss: 0.6902 - val_loss: 0.6881\n",
      "Epoch 3/150\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.6853 - val_loss: 0.6819\n",
      "Epoch 4/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.6764 - val_loss: 0.6693\n",
      "Epoch 5/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.6549 - val_loss: 0.6336\n",
      "Epoch 6/150\n",
      "60000/60000 [==============================] - 143s 2ms/sample - loss: 0.5851 - val_loss: 0.5261\n",
      "Epoch 7/150\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 0.4970 - val_loss: 0.4896\n",
      "Epoch 8/150\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 0.4818 - val_loss: 0.4813\n",
      "Epoch 9/150\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 0.4737 - val_loss: 0.4732\n",
      "Epoch 10/150\n",
      "60000/60000 [==============================] - 151s 3ms/sample - loss: 0.4657 - val_loss: 0.4653\n",
      "Epoch 11/150\n",
      "60000/60000 [==============================] - 152s 3ms/sample - loss: 0.4580 - val_loss: 0.4575\n",
      "Epoch 12/150\n",
      "60000/60000 [==============================] - 156s 3ms/sample - loss: 0.4501 - val_loss: 0.4493\n",
      "Epoch 13/150\n",
      "60000/60000 [==============================] - 153s 3ms/sample - loss: 0.4417 - val_loss: 0.4405\n",
      "Epoch 14/150\n",
      "60000/60000 [==============================] - 153s 3ms/sample - loss: 0.4326 - val_loss: 0.4310\n",
      "Epoch 15/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.4228 - val_loss: 0.4205\n",
      "Epoch 16/150\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.4120 - val_loss: 0.4090\n",
      "Epoch 17/150\n",
      "60000/60000 [==============================] - 143s 2ms/sample - loss: 0.4000 - val_loss: 0.3962\n",
      "Epoch 18/150\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 0.3866 - val_loss: 0.3818\n",
      "Epoch 19/150\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.3715 - val_loss: 0.3656\n",
      "Epoch 20/150\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.3547 - val_loss: 0.3476\n",
      "Epoch 21/150\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.3365 - val_loss: 0.3285\n",
      "Epoch 22/150\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.3181 - val_loss: 0.3107\n",
      "Epoch 23/150\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 0.3025 - val_loss: 0.2968\n",
      "Epoch 24/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2909 - val_loss: 0.2871\n",
      "Epoch 25/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.2829 - val_loss: 0.2802\n",
      "Epoch 26/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.2770 - val_loss: 0.2750\n",
      "Epoch 27/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.2726 - val_loss: 0.2711\n",
      "Epoch 28/150\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 0.2690 - val_loss: 0.2678\n",
      "Epoch 29/150\n",
      "60000/60000 [==============================] - 148s 2ms/sample - loss: 0.2660 - val_loss: 0.2649\n",
      "Epoch 30/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2633 - val_loss: 0.2622\n",
      "Epoch 31/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.2608 - val_loss: 0.2597\n",
      "Epoch 32/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.2584 - val_loss: 0.2573\n",
      "Epoch 33/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.2561 - val_loss: 0.2550\n",
      "Epoch 34/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.2539 - val_loss: 0.2528\n",
      "Epoch 35/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.2518 - val_loss: 0.2507\n",
      "Epoch 36/150\n",
      "60000/60000 [==============================] - 148s 2ms/sample - loss: 0.2497 - val_loss: 0.2487\n",
      "Epoch 37/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2477 - val_loss: 0.2467\n",
      "Epoch 38/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2458 - val_loss: 0.2448\n",
      "Epoch 39/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2440 - val_loss: 0.2429\n",
      "Epoch 40/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2421 - val_loss: 0.2411\n",
      "Epoch 41/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2403 - val_loss: 0.2393\n",
      "Epoch 42/150\n",
      "60000/60000 [==============================] - 150s 2ms/sample - loss: 0.2386 - val_loss: 0.2376\n",
      "Epoch 43/150\n",
      "60000/60000 [==============================] - 148s 2ms/sample - loss: 0.2369 - val_loss: 0.2358\n",
      "Epoch 44/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2352 - val_loss: 0.2341\n",
      "Epoch 45/150\n",
      "60000/60000 [==============================] - 148s 2ms/sample - loss: 0.2335 - val_loss: 0.2325\n",
      "Epoch 46/150\n",
      "60000/60000 [==============================] - 148s 2ms/sample - loss: 0.2319 - val_loss: 0.2308\n",
      "Epoch 47/150\n",
      "60000/60000 [==============================] - 152s 3ms/sample - loss: 0.2303 - val_loss: 0.2292\n",
      "Epoch 48/150\n",
      "60000/60000 [==============================] - 150s 3ms/sample - loss: 0.2287 - val_loss: 0.2276\n",
      "Epoch 49/150\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 0.2272 - val_loss: 0.2261\n",
      "Epoch 50/150\n",
      "60000/60000 [==============================] - 150s 2ms/sample - loss: 0.2257 - val_loss: 0.2247\n",
      "Epoch 51/150\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 0.2243 - val_loss: 0.2233\n",
      "Epoch 52/150\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 0.2231 - val_loss: 0.2220\n",
      "Epoch 53/150\n",
      "60000/60000 [==============================] - 150s 3ms/sample - loss: 0.2219 - val_loss: 0.2209\n",
      "Epoch 54/150\n",
      "60000/60000 [==============================] - 156s 3ms/sample - loss: 0.2208 - val_loss: 0.2198\n",
      "Epoch 55/150\n",
      "60000/60000 [==============================] - 150s 3ms/sample - loss: 0.2197 - val_loss: 0.2188\n",
      "Epoch 56/150\n",
      "60000/60000 [==============================] - 150s 3ms/sample - loss: 0.2188 - val_loss: 0.2178\n",
      "Epoch 57/150\n",
      "60000/60000 [==============================] - 151s 3ms/sample - loss: 0.2179 - val_loss: 0.2170\n",
      "Epoch 58/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2171 - val_loss: 0.2162\n",
      "Epoch 59/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2163 - val_loss: 0.2154\n",
      "Epoch 60/150\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 0.2156 - val_loss: 0.2147\n",
      "Epoch 61/150\n",
      "60000/60000 [==============================] - 148s 2ms/sample - loss: 0.2149 - val_loss: 0.2140\n",
      "Epoch 62/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2143 - val_loss: 0.2134\n",
      "Epoch 63/150\n",
      "60000/60000 [==============================] - 148s 2ms/sample - loss: 0.2137 - val_loss: 0.2128\n",
      "Epoch 64/150\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 0.2131 - val_loss: 0.2123\n",
      "Epoch 65/150\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 0.2126 - val_loss: 0.2117\n",
      "Epoch 66/150\n",
      "60000/60000 [==============================] - 150s 3ms/sample - loss: 0.2120 - val_loss: 0.2112\n",
      "Epoch 67/150\n",
      "60000/60000 [==============================] - 155s 3ms/sample - loss: 0.2115 - val_loss: 0.2107\n",
      "Epoch 68/150\n",
      "60000/60000 [==============================] - 150s 2ms/sample - loss: 0.2110 - val_loss: 0.2102\n",
      "Epoch 69/150\n",
      "60000/60000 [==============================] - 150s 2ms/sample - loss: 0.2105 - val_loss: 0.2097\n",
      "Epoch 70/150\n",
      "60000/60000 [==============================] - 150s 3ms/sample - loss: 0.2101 - val_loss: 0.2092\n",
      "Epoch 71/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.2096 - val_loss: 0.2088\n",
      "Epoch 72/150\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 0.2092 - val_loss: 0.2083\n",
      "Epoch 73/150\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 0.2087 - val_loss: 0.2079\n",
      "Epoch 74/150\n",
      "60000/60000 [==============================] - 142s 2ms/sample - loss: 0.2083 - val_loss: 0.2075\n",
      "Epoch 75/150\n",
      "60000/60000 [==============================] - 140s 2ms/sample - loss: 0.2079 - val_loss: 0.2070\n",
      "Epoch 76/150\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 0.2075 - val_loss: 0.2066\n",
      "Epoch 77/150\n",
      "60000/60000 [==============================] - 140s 2ms/sample - loss: 0.2071 - val_loss: 0.2062\n",
      "Epoch 78/150\n",
      "60000/60000 [==============================] - 142s 2ms/sample - loss: 0.2067 - val_loss: 0.2058\n",
      "Epoch 79/150\n",
      "60000/60000 [==============================] - 143s 2ms/sample - loss: 0.2063 - val_loss: 0.2054\n",
      "Epoch 80/150\n",
      "60000/60000 [==============================] - 142s 2ms/sample - loss: 0.2059 - val_loss: 0.2050\n",
      "Epoch 81/150\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 0.2055 - val_loss: 0.2046\n",
      "Epoch 82/150\n",
      "60000/60000 [==============================] - 142s 2ms/sample - loss: 0.2051 - val_loss: 0.2042\n",
      "Epoch 83/150\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 0.2048 - val_loss: 0.2039\n",
      "Epoch 84/150\n",
      "60000/60000 [==============================] - 142s 2ms/sample - loss: 0.2044 - val_loss: 0.2035\n",
      "Epoch 85/150\n",
      "60000/60000 [==============================] - 144s 2ms/sample - loss: 0.2040 - val_loss: 0.2031\n",
      "Epoch 86/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.2037 - val_loss: 0.2028\n",
      "Epoch 87/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.2033 - val_loss: 0.2024\n",
      "Epoch 88/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.2029 - val_loss: 0.2021\n",
      "Epoch 89/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.2026 - val_loss: 0.2017\n",
      "Epoch 90/150\n",
      "60000/60000 [==============================] - 140s 2ms/sample - loss: 0.2022 - val_loss: 0.2013\n",
      "Epoch 91/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.2019 - val_loss: 0.2010\n",
      "Epoch 92/150\n",
      "60000/60000 [==============================] - 140s 2ms/sample - loss: 0.2015 - val_loss: 0.2006\n",
      "Epoch 93/150\n",
      "60000/60000 [==============================] - 140s 2ms/sample - loss: 0.2012 - val_loss: 0.2003\n",
      "Epoch 94/150\n",
      "60000/60000 [==============================] - 140s 2ms/sample - loss: 0.2009 - val_loss: 0.1999\n",
      "Epoch 95/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.2005 - val_loss: 0.1996\n",
      "Epoch 96/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.2002 - val_loss: 0.1993\n",
      "Epoch 97/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.1998 - val_loss: 0.1989\n",
      "Epoch 98/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.1995 - val_loss: 0.1986\n",
      "Epoch 99/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.1992 - val_loss: 0.1983\n",
      "Epoch 100/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.1989 - val_loss: 0.1979\n",
      "Epoch 101/150\n",
      "60000/60000 [==============================] - 136s 2ms/sample - loss: 0.1985 - val_loss: 0.1976\n",
      "Epoch 102/150\n",
      "60000/60000 [==============================] - 135s 2ms/sample - loss: 0.1982 - val_loss: 0.1973\n",
      "Epoch 103/150\n",
      "60000/60000 [==============================] - 136s 2ms/sample - loss: 0.1979 - val_loss: 0.1970\n",
      "Epoch 104/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.1976 - val_loss: 0.1967\n",
      "Epoch 105/150\n",
      "60000/60000 [==============================] - 136s 2ms/sample - loss: 0.1973 - val_loss: 0.1964\n",
      "Epoch 106/150\n",
      "60000/60000 [==============================] - 137s 2ms/sample - loss: 0.1970 - val_loss: 0.1960\n",
      "Epoch 107/150\n",
      "60000/60000 [==============================] - 136s 2ms/sample - loss: 0.1967 - val_loss: 0.1957\n",
      "Epoch 108/150\n",
      "60000/60000 [==============================] - 136s 2ms/sample - loss: 0.1964 - val_loss: 0.1954\n",
      "Epoch 109/150\n",
      "60000/60000 [==============================] - 136s 2ms/sample - loss: 0.1961 - val_loss: 0.1951\n",
      "Epoch 110/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.1958 - val_loss: 0.1948\n",
      "Epoch 111/150\n",
      "60000/60000 [==============================] - 137s 2ms/sample - loss: 0.1954 - val_loss: 0.1945\n",
      "Epoch 112/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.1952 - val_loss: 0.1942\n",
      "Epoch 113/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.1949 - val_loss: 0.1939\n",
      "Epoch 114/150\n",
      "60000/60000 [==============================] - 139s 2ms/sample - loss: 0.1946 - val_loss: 0.1936\n",
      "Epoch 115/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.1943 - val_loss: 0.1933\n",
      "Epoch 116/150\n",
      "60000/60000 [==============================] - 137s 2ms/sample - loss: 0.1940 - val_loss: 0.1931\n",
      "Epoch 117/150\n",
      "60000/60000 [==============================] - 136s 2ms/sample - loss: 0.1937 - val_loss: 0.1928\n",
      "Epoch 118/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.1934 - val_loss: 0.1925\n",
      "Epoch 119/150\n",
      "60000/60000 [==============================] - 137s 2ms/sample - loss: 0.1931 - val_loss: 0.1922\n",
      "Epoch 120/150\n",
      "60000/60000 [==============================] - 132s 2ms/sample - loss: 0.1929 - val_loss: 0.1919\n",
      "Epoch 121/150\n",
      "60000/60000 [==============================] - 135s 2ms/sample - loss: 0.1926 - val_loss: 0.1916\n",
      "Epoch 122/150\n",
      "60000/60000 [==============================] - 134s 2ms/sample - loss: 0.1923 - val_loss: 0.1913\n",
      "Epoch 123/150\n",
      "60000/60000 [==============================] - 138s 2ms/sample - loss: 0.1920 - val_loss: 0.1911\n",
      "Epoch 124/150\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 0.1917 - val_loss: 0.1908\n",
      "Epoch 125/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.1915 - val_loss: 0.1905\n",
      "Epoch 126/150\n",
      "60000/60000 [==============================] - 146s 2ms/sample - loss: 0.1912 - val_loss: 0.1903\n",
      "Epoch 127/150\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 0.1909 - val_loss: 0.1900\n",
      "Epoch 128/150\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 0.1907 - val_loss: 0.1897\n",
      "Epoch 129/150\n",
      "60000/60000 [==============================] - 160s 3ms/sample - loss: 0.1904 - val_loss: 0.1895\n",
      "Epoch 130/150\n",
      "60000/60000 [==============================] - 150s 2ms/sample - loss: 0.1902 - val_loss: 0.1892\n",
      "Epoch 131/150\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 0.1899 - val_loss: 0.1889\n",
      "Epoch 132/150\n",
      "60000/60000 [==============================] - 140s 2ms/sample - loss: 0.1896 - val_loss: 0.1887\n",
      "Epoch 133/150\n",
      "60000/60000 [==============================] - 131s 2ms/sample - loss: 0.1894 - val_loss: 0.1884\n",
      "Epoch 134/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1891 - val_loss: 0.1882\n",
      "Epoch 135/150\n",
      "60000/60000 [==============================] - 134s 2ms/sample - loss: 0.1889 - val_loss: 0.1879\n",
      "Epoch 136/150\n",
      "60000/60000 [==============================] - 134s 2ms/sample - loss: 0.1886 - val_loss: 0.1877\n",
      "Epoch 137/150\n",
      "60000/60000 [==============================] - 134s 2ms/sample - loss: 0.1884 - val_loss: 0.1874\n",
      "Epoch 138/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1881 - val_loss: 0.1872\n",
      "Epoch 139/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1879 - val_loss: 0.1869\n",
      "Epoch 140/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1876 - val_loss: 0.1867\n",
      "Epoch 141/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1874 - val_loss: 0.1864\n",
      "Epoch 142/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1871 - val_loss: 0.1862\n",
      "Epoch 143/150\n",
      "60000/60000 [==============================] - 132s 2ms/sample - loss: 0.1869 - val_loss: 0.1859\n",
      "Epoch 144/150\n",
      "60000/60000 [==============================] - 134s 2ms/sample - loss: 0.1866 - val_loss: 0.1857\n",
      "Epoch 145/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1864 - val_loss: 0.1854\n",
      "Epoch 146/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1862 - val_loss: 0.1852\n",
      "Epoch 147/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1859 - val_loss: 0.1850\n",
      "Epoch 148/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1857 - val_loss: 0.1847\n",
      "Epoch 149/150\n",
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.1855 - val_loss: 0.1845\n",
      "Epoch 150/150\n",
      "60000/60000 [==============================] - 134s 2ms/sample - loss: 0.1852 - val_loss: 0.1842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1da08746400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=150,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "autoencoder.save(MODEL_PATH + 'autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test[:10])\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore model used for unsupervised pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_autoencoder = keras.models.load_model(MODEL_PATH + 'autoencoder.h5')\n",
    "pretrained_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding layers at the end of the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pretrained_autoencoder.output\n",
    "# Adding a fully connected layers\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "# Adding a fully connected layer for the 10 classes 0 to 9\n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### freezing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=pretrained_autoencoder.input, outputs=predictions)\n",
    "\n",
    "# freeze all layers of the pre-trained model\n",
    "# we will only train the Dense layers added in \"model\"\n",
    "for layer in pretrained_autoencoder.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with adam optimizer and sparse_categorical_crossentropy loss function\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
