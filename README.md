# transfer_learning_and_unsupervised_pre-training
 
Learning how to do transfert learning and how to properly use an unsupervised pre-training.

In this repo, I wanted to test how to get better results with few data:

1- increasing the dataset artificially (zoom, rotation, constrast, ... or using an ImageDataGenerator).

2- Transfer Learning: training a neural network which has been already trained for a similar task.

3- Unsupervised pre-training (if we have enough data but few have a label): using a convolutional autoencoder.
